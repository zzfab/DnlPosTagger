num_classes: 66
output_dim: 1
dropout: 0.1

optim:
  lr: 1e-4
  weight_decay: 1e-8
  amsgrad: False

text:
  model_type: "BERTClassifier" # BERTClassifier, FastTextClassifier
  pretrained_model: "bert-base-uncased"
  dim_after_pad: 128 # 64

  # for n page
  sentence_level:
    input_size: 768
    hidden_size: 1024
    bias: False
    attention: False

scheduler:
  patience: 5   # number of intervals to wait before updating lr
  factor: 0.1   # quantity to update lr by, divides lr by factor
  min_lr: 1e-5  # does not update lr to be smaller than this
  verbose: True
  monitor: "loss/val"  # quantity to monitor to determine need for lr update
  interval: "epoch"   # epoch or step
  frequency: 5
